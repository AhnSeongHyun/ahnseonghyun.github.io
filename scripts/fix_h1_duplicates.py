#!/usr/bin/env python3
"""
H1 Duplicate Remover

Fixes files with multiple H1 headings by converting all H1s after the first one to H2s.
Always creates backup files (filename_bak.md) before modification.
"""

import re
import shutil
from pathlib import Path
from typing import Tuple, Optional


class H1DuplicateFixer:
    def __init__(self, dry_run=False):
        self.dry_run = dry_run

    def parse_frontmatter(self, content: str) -> Tuple[Optional[str], str]:
        """
        Parse frontmatter and body

        Returns:
            (frontmatter, body) tuple
        """
        pattern = r'^---\s*\n(.*?)\n---\s*\n(.*)$'
        match = re.match(pattern, content, re.DOTALL)

        if match:
            frontmatter = match.group(1)
            body = match.group(2)
            return f"---\n{frontmatter}\n---\n\n", body
        else:
            return None, content

    def count_h1_headings(self, text: str) -> int:
        """Count H1 headings in markdown text"""
        # Match lines that start with exactly one # followed by a space
        pattern = r'^# [^\n]+'
        matches = re.findall(pattern, text, re.MULTILINE)
        return len(matches)

    def fix_h1_duplicates(self, body: str) -> Tuple[str, int]:
        """
        Convert all H1 headings after the first one to H2

        Returns:
            (fixed_body, number_of_fixes)
        """
        lines = body.split('\n')
        fixed_lines = []
        h1_count = 0
        fixes = 0

        for line in lines:
            # Check if line is an H1 heading (starts with # but not ##)
            if re.match(r'^# [^\n]+', line):
                h1_count += 1

                if h1_count == 1:
                    # Keep first H1
                    fixed_lines.append(line)
                else:
                    # Convert to H2
                    fixed_lines.append('#' + line)
                    fixes += 1
            else:
                fixed_lines.append(line)

        return '\n'.join(fixed_lines), fixes

    def backup_file(self, filepath: Path) -> Path:
        """Create backup file"""
        backup_path = filepath.parent / f"{filepath.stem}_bak.md"

        if backup_path.exists():
            # Backup already exists
            return backup_path

        shutil.copy2(filepath, backup_path)
        print(f"  âœ… ë°±ì—… ìƒì„±: {backup_path.name}")
        return backup_path

    def fix_file(self, filepath: Path, min_h1_count: int = 2) -> bool:
        """
        Fix H1 duplicates in a single file

        Args:
            filepath: File to fix
            min_h1_count: Minimum H1 count to trigger fixing (default: 2)

        Returns:
            True if changes were made, False otherwise
        """
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                content = f.read()

            frontmatter_section, body = self.parse_frontmatter(content)

            # Count H1 headings
            h1_count = self.count_h1_headings(body)

            if h1_count < min_h1_count:
                return False

            print(f"\nğŸ“ ìˆ˜ì • ì¤‘: {filepath.name}")
            print(f"  H1 ê°œìˆ˜: {h1_count}ê°œ")

            # Fix H1 duplicates
            fixed_body, fixes = self.fix_h1_duplicates(body)

            print(f"  ë³€ê²½: {fixes}ê°œ H1 â†’ H2 ë³€í™˜")

            if self.dry_run:
                print("  ğŸ” [DRY RUN] ë³€ê²½ì‚¬í•­ ë¯¸ì €ì¥")
                return True

            # Backup original file
            self.backup_file(filepath)

            # Reconstruct file
            if frontmatter_section:
                new_content = frontmatter_section + fixed_body
            else:
                new_content = fixed_body

            # Save fixed version
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(new_content)

            print("  âœ… ì €ì¥ ì™„ë£Œ")
            return True

        except Exception as e:
            print(f"  âŒ ì˜¤ë¥˜: {str(e)}")
            return False

    def fix_directory(self, directory: Path, year_filter: int = 2020,
                     max_files: Optional[int] = None):
        """
        Fix H1 duplicates in all markdown files in directory

        Args:
            directory: Target directory
            year_filter: Only process files from this year onwards
            max_files: Maximum number of files to process
        """
        md_files = list(directory.glob('**/*.md'))

        # Exclude _bak.md files
        md_files = [f for f in md_files if not f.stem.endswith('_bak')]

        # Filter by H1 count
        files_to_fix = []
        for filepath in md_files:
            try:
                with open(filepath, 'r', encoding='utf-8') as f:
                    content = f.read()
                _, body = self.parse_frontmatter(content)
                h1_count = self.count_h1_headings(body)

                if h1_count >= 2:
                    files_to_fix.append((filepath, h1_count))
            except Exception:
                continue

        # Sort by H1 count (descending)
        files_to_fix.sort(key=lambda x: x[1], reverse=True)

        print(f"\n{'='*60}")
        print("H1 ì¤‘ë³µ ì œê±°")
        print(f"{'='*60}")
        print(f"ëŒ€ìƒ ë””ë ‰í† ë¦¬: {directory}")
        print(f"H1 ì¤‘ë³µ íŒŒì¼: {len(files_to_fix)}ê°œ")
        if max_files:
            print(f"ìµœëŒ€ ì²˜ë¦¬ íŒŒì¼: {max_files}ê°œ")
        if self.dry_run:
            print("âš ï¸  DRY RUN ëª¨ë“œ (ì‹¤ì œ ì €ì¥ ì•ˆí•¨)")
        print(f"{'='*60}\n")

        if files_to_fix:
            print("íŒŒì¼ ëª©ë¡:")
            for filepath, h1_count in files_to_fix[:10]:  # Show first 10
                print(f"  â€¢ {filepath.name} ({h1_count}ê°œ H1)")
            if len(files_to_fix) > 10:
                print(f"  ... ì™¸ {len(files_to_fix) - 10}ê°œ")
            print()

        fixed = 0
        skipped = 0
        failed = 0

        for filepath, h1_count in files_to_fix:
            if max_files and fixed >= max_files:
                print(f"\nâ¹ï¸  ìµœëŒ€ ì²˜ë¦¬ íŒŒì¼ ìˆ˜({max_files})ì— ë„ë‹¬")
                break

            result = self.fix_file(filepath)

            if result is True:
                fixed += 1
            elif result is False:
                skipped += 1
            else:
                failed += 1

        # Summary
        print(f"\n{'='*60}")
        print("ìˆ˜ì • ì™„ë£Œ")
        print(f"{'='*60}")
        print(f"âœ… ìˆ˜ì • ì™„ë£Œ: {fixed}ê°œ")
        print(f"â­ï¸  ê±´ë„ˆë›´ íŒŒì¼: {skipped}ê°œ")
        if failed > 0:
            print(f"âŒ ì‹¤íŒ¨: {failed}ê°œ")
        print(f"{'='*60}\n")


def main():
    import argparse

    parser = argparse.ArgumentParser(description='H1 ì¤‘ë³µ ì œê±°')
    parser.add_argument('--year', type=int, default=2020,
                       help='ì´ ë…„ë„ ì´í›„ íŒŒì¼ë§Œ ì²˜ë¦¬ (ê¸°ë³¸: 2020)')
    parser.add_argument('--max-files', type=int, default=None,
                       help='ìµœëŒ€ ì²˜ë¦¬ íŒŒì¼ ìˆ˜')
    parser.add_argument('--dry-run', action='store_true',
                       help='ì‹¤ì œ ë³€í™˜í•˜ì§€ ì•Šê³  í…ŒìŠ¤íŠ¸ë§Œ')
    parser.add_argument('--directory', type=str, default='contents',
                       help='ëŒ€ìƒ ë””ë ‰í† ë¦¬ (ê¸°ë³¸: contents)')

    args = parser.parse_args()

    fixer = H1DuplicateFixer(dry_run=args.dry_run)
    fixer.fix_directory(
        directory=Path(args.directory),
        year_filter=args.year,
        max_files=args.max_files
    )


if __name__ == '__main__':
    main()
